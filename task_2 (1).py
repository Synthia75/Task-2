# -*- coding: utf-8 -*-
"""Task_2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1K6tjBGoRncRHmhy-m25LgOX9eh8xkm7S
"""

!pip install PyPDF2
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import networkx as nx
from PyPDF2 import PdfReader
def main():
  file_path = '/content/Synthia_Tabassum_Workflow_Simulation_and_Optimization_Analysis.csv'
  data = pd.read_csv(file_path)
  print(data.head())
# 1. Data Import and Validation
def import_and_validate_data(csv_file_path):
    # Import data
    data = pd.read_csv(csv_file_path)

    # Validate task dependencies (no circular dependencies)
    G = nx.DiGraph()
    for _, row in data.iterrows():
        G.add_edge(row['Dependency'], row['Task_Category'])

    if not nx.is_directed_acyclic_graph(G):
        raise ValueError("Circular dependencies detected in the workflow.")

    return data, G

# 2. Workflow Analysis
def calculate_predicted_completion_times(data):
    task_times = {}
    for task in data['Task_Category']:
        predecessors = data[data['Task_Category'] == task]['Dependency'].values
        max_time = max([task_times.get(p, 0) for p in predecessors if p != 'None'], default=0)
        task_times[task] = max_time + data[data['Task_Category'] == task]['Predicted_Time (min)'].values[0]
    return task_times

def identify_delays(data, task_times):
    delays = {}
    for _, row in data.iterrows():
        predicted = task_times[row['Task_Category']]
        actual = row['Actual_Time (min)']
        delays[row['Task_Category']] = actual - predicted
    return delays

def compute_total_workflow_time(data, task_times):
    return max(task_times.values())

# 3. Optimization Recommendations
def recommend_resource_reallocation(data, task_times):
    critical_path = nx.dag_longest_path(nx.DiGraph([(row['Dependency'], row['Task_Category']) for _, row in data.iterrows()]))
    resource_usage = data.groupby('Resource_Usages (%)')['Precdicted_Time (min)'].sum()
    recommendations = {resource: 'Increase allocation' for resource in resource_usage.idxmax()}
    return critical_path, recommendations

# 4. Visualization
def create_gantt_chart(data, task_times):
    plt.barh(data['Task_Category'], data['Predicted_Time (min)'], left=[task_times[task] - data[data['Task_Category'] == task]['Predicted_Time (min)'].values[0] for task in data['Task_Category']])
    plt.xlabel('Time')
    plt.title('Gantt Chart')
    plt.show()


def create_network_diagram(G):
    plt.figure(figsize=(10, 6))
    pos = nx.spring_layout(G)
    nx.draw(G, pos, with_labels=True, node_size=2000, node_color='skyblue', font_size=10, font_weight='bold')
    plt.title('Task Dependency Network')
    plt.show()

def create_bar_chart(data, delays):
    plt.bar(data['Task_Category'], [delays[task] for task in data['Task_Category']])
    plt.xlabel('Tasks')
    plt.ylabel('Delay (Time Units)')
    plt.title('Predicted vs. Actual Task Completion Times')
    plt.show()

# Main Function
def main():
    csv_file_path = '/content/Synthia_Tabassum_Workflow_Simulation_and_Optimization_Analysis.csv'


    # Step 1: Data Import and Validation
    data, G = import_and_validate_data(csv_file_path)

    # Step 2: Workflow Analysis
    task_times = calculate_predicted_completion_times(data)
    delays = identify_delays(data, task_times)
    total_time = compute_total_workflow_time(data, task_times)

    print("Predicted Completion Times:")
    print(task_times)
    print("\nTask Delays:")
    print(delays)
    print(f"\nTotal Workflow Time: {total_time}")

    # Step 3: Optimization Recommendations
    critical_path, recommendations = recommend_resource_reallocation(data, task_times)
    print("\nCritical Path:")
    print(critical_path)
    print("\nResource Allocation Recommendations:")
    print(recommendations)

    # Step 4: Visualization
    create_gantt_chart(data, task_times)
    create_network_diagram(G)
    create_bar_chart(data, delays)

if __name__ == "__main__":
    main()